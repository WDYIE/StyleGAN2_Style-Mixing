{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleMixing with StyleGAN2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_s8h-ilzHQc",
        "colab_type": "text"
      },
      "source": [
        "# StyleGAN2 -> Style-Mixing\n",
        "\n",
        "***AmirHossein Bayat & Melika Emami***\n",
        "\n",
        "This notebook demonstrates how to run NVIDIA's StyleGAN2 on Google Colab to do Style Mixing With your custom photo.\n",
        "Make sure to specify a GPU runtime.\n",
        "\n",
        "For information on StyleGAN2, see:\n",
        "\n",
        "Paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "Video: https://youtu.be/kSLJriaOumA\n",
        "\n",
        "Code: https://github.com/NVlabs/stylegan\n",
        "\n",
        "FFHQ: https://github.com/NVlabs/ffhq-dataset\n",
        "\n",
        "/Mikael Christensen, 2019.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzDuIoMcqfBT",
        "colab_type": "code",
        "outputId": "74e426de-a0f1-4b53-d1a0-2ea36994263a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan2.git\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Total 93 (delta 0), reused 0 (delta 0), pack-reused 93\u001b[K\n",
            "Unpacking objects: 100% (93/93), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n",
            "Tensorflow version: 1.15.0\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-db91432b-5bb8-0555-f370-71f884bb181b)\n",
            "GPU Identified at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz23RJ-RgPME",
        "colab_type": "code",
        "outputId": "0966d8ab-98a0-4f40-e6bb-5c970a0f706b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupSIgCZ3rj7",
        "colab_type": "text"
      },
      "source": [
        "**Required Files**\n",
        "\n",
        "Now you need to add below files to your google drive. Make sure you change path of files if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R-VCNwhgedt",
        "colab_type": "code",
        "outputId": "80fbf5bb-56d0-4f97-8238-3fae262a5db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Projector files to convert given photos to dlatent vectors. I've changed a few things in original files from StyleGAN2, so you need to upload these files.\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/run_projector.py\" \"/content/stylegan2/run_projector.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/projector.py\" \"/content/stylegan2/projector.py\"\n",
        "# These files are used to align the given pictures and export the face part from it.\n",
        "!mkdir ffhq_dataset\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/__init__.py\" \"/content/stylegan2/ffhq_dataset/__init__.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/face_alignment.py\" \"/content/stylegan2/ffhq_dataset/face_alignment.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/landmarks_detector.py\" \"/content/stylegan2/ffhq_dataset/landmarks_detector.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/align_images.py\" \"/content/stylegan2/align_images.py\"\n",
        "# In this part you have to specify your custom pictures to be used. I've named my pictures like below.\n",
        "!mkdir Pictures\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic1.JPG\" \"/content/stylegan2/Pictures/Pic1.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic2.JPG\" \"/content/stylegan2/Pictures/Pic2.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic3.JPG\" \"/content/stylegan2/Pictures/Pic3.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic4.jpg\" \"/content/stylegan2/Pictures/Pic4.JPG\"\n",
        "# Make a folder to save aligned pictures in it.\n",
        "!mkdir aligned_pictures"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!mkdir ffhq_dataset\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/__init__.py\" \"/content/stylegan2/ffhq_dataset/__init__.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/face_alignment.py\" \"/content/stylegan2/ffhq_dataset/face_alignment.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/landmarks_detector.py\" \"/content/stylegan2/ffhq_dataset/landmarks_detector.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/align_images.py\" \"/content/stylegan2/align_images.py\"\\n!mkdir Pictures\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic1.JPG\" \"/content/stylegan2/Pictures/Pic1.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic2.JPG\" \"/content/stylegan2/Pictures/Pic2.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic3.JPG\" \"/content/stylegan2/Pictures/Pic3.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic4.jpg\" \"/content/stylegan2/Pictures/Pic4.JPG\"\\n!mkdir aligned_pictures'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFF5yfvA5UNz",
        "colab_type": "text"
      },
      "source": [
        "**Aligning Pictures**\n",
        "\n",
        "Now you need to run the align_images.py to do the aligning. Parameters are the folder containing your pictures and the folder to save the aligned pictures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoxEbwwtjkwO",
        "colab_type": "code",
        "outputId": "53e68504-72a3-4d7d-c7a5-3c82f767a56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%run align_images.py Pictures/ aligned_pictures/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "64045056/64040097 [==============================] - 173s 3us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pen-j5ij5s6j",
        "colab_type": "text"
      },
      "source": [
        "**Generate .tfrecords**\n",
        "\n",
        "We use the dataset_tool.py from StyleGAN2 to convert aligned pictures to tfrecords files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC_I6IOjc1KT",
        "colab_type": "code",
        "outputId": "781fc81a-a3c2-4570-efe6-789531af7f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%run dataset_tool.py create_from_images Datasets aligned_pictures"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images from \"aligned_pictures\"\n",
            "Creating dataset \"Datasets\"\n",
            "Added 4 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyIv8Svm6EVc",
        "colab_type": "text"
      },
      "source": [
        "**Projecting pictures**\n",
        "\n",
        "In this part we use our customized run_projector.py file to the image projection. We set the network parameter to StyleGAN2-ffhq-config-f and Project only one of our converted pictures. (You can change the --num-images to whatever you want. The default step parameter for this part is set to 1500 which you can change on **projector.py** file. After running this part some .npy files containing dlatents will generate in results folder related to each picture.(There's a little bug here which does not affect our work.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNg_QellgTnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%run run_projector.py project-real-images --network=gdrive:networks/stylegan2-ffhq-config-f.pkl --dataset=Datasets --data-dir=. --num-images=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKxs_BHp7KcB",
        "colab_type": "text"
      },
      "source": [
        "**Style Mixing Function**\n",
        "\n",
        "In this function we load the network and use it to map some given seed to dlatent vectors as **Style**. The dlatent parameter is the loaded .npy files which we generated in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J7Rqn8BDY-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "def style_mixing(dlatent, col_seeds, truncation_psi, col_styles, minibatch_size=4):\n",
        "    print('Loading networks from ...')\n",
        "    _G, _D, Gs = pretrained_networks.load_networks('gdrive:networks/stylegan2-ffhq-config-f.pkl')\n",
        "    w_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "    row_seeds = [80]\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = False\n",
        "    Gs_syn_kwargs.minibatch_size = 1 #minibatch_size\n",
        "\n",
        "    print('Generating W vectors...')\n",
        "    all_seeds = list(set(col_seeds))\n",
        "    all_z = np.stack([np.random.RandomState(seed).randn(*Gs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
        "\n",
        "    all_w = Gs.components.mapping.run(all_z, None) # [minibatch, layer, component]\n",
        "    all_w = np.concatenate((all_w, dlatent), 0)\n",
        "    all_w = w_avg + (all_w - w_avg) * truncation_psi # [minibatch, layer, component]\n",
        "    all_seeds.extend(row_seeds) #= list(set(col_seeds + row_seeds))\n",
        "    w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))} # [layer, component]\n",
        "    \n",
        "    print('Generating images...')\n",
        "    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs) # [minibatch, height, width, channel]\n",
        "    image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n",
        "\n",
        "    print('Generating style-mixed images...')\n",
        "    for row_seed in row_seeds:\n",
        "        for col_seed in col_seeds:\n",
        "            w = w_dict[row_seed].copy()\n",
        "            # We set col_styles in this part\n",
        "            w[3:8] = w_dict[col_seed][3:8]\n",
        "            image = Gs.components.synthesis.run(w[np.newaxis], **Gs_syn_kwargs)[0]\n",
        "            image_dict[(row_seed, col_seed)] = image\n",
        "\n",
        "    print('Saving images...')\n",
        "    for (row_seed, col_seed), image in image_dict.items():\n",
        "        PIL.Image.fromarray(image, 'RGB').save(dnnlib.make_run_dir_path('Mix/'+'%d-%d.png' % (row_seed, col_seed)))\n",
        "\n",
        "    print('Saving image grid...')\n",
        "    _N, _C, H, W = Gs.output_shape\n",
        "    canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n",
        "    for row_idx, row_seed in enumerate([None] + row_seeds):\n",
        "        for col_idx, col_seed in enumerate([None] + col_seeds):\n",
        "            if row_seed is None and col_seed is None:\n",
        "                continue\n",
        "            key = (row_seed, col_seed)\n",
        "            if row_seed is None:\n",
        "                key = (col_seed, col_seed)\n",
        "            if col_seed is None:\n",
        "                key = (row_seed, row_seed)\n",
        "            canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx))\n",
        "    canvas.save(dnnlib.make_run_dir_path('Mix/grid.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1uw5q9580as",
        "colab_type": "text"
      },
      "source": [
        "Load some dlatent.npy file and pass it to function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5eZxw9DqIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dlat = np.load('/content/stylegan2/results/00002-project-real-images/image0000--dlatent.npy')\n",
        "style_mixing(dlat, [44,55,1000,10,3,100,75,458,1500], 0.5, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_HRi6eR8_Tu",
        "colab_type": "text"
      },
      "source": [
        "If you want to zip results folder to download it run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZWBP43KSx5U",
        "colab_type": "code",
        "outputId": "1c8a3dbf-0d40-4aca-dfb6-3762bcfda24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import shutil\n",
        "\n",
        "zip_name = '/content/stylegan2/resultszip'\n",
        "directory_name = '/content/stylegan2/results'\n",
        "\n",
        "# Create 'path\\to\\zip_file.zip'\n",
        "shutil.make_archive(zip_name, 'zip', directory_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/stylegan2/resultszip.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}